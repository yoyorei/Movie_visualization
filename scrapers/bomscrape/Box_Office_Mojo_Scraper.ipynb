{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movie Maps\n",
    "---\n",
    "Webscrapper for Movie data.\n",
    "---\n",
    "### Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from splinter import Browser\n",
    "from os.path import basename\n",
    "from pprint import pprint\n",
    "import time\n",
    "from datetime import datetime as dt\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splinter set up\n",
    "executable_path = {'executable_path': 'chromedriver.exe'}\n",
    "browser = Browser('chrome', **executable_path, headless=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Extraction\n",
    "- Scrape data off of Box Office Mojo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeMovies(id_url, data_url):\n",
    "    browser.visit(id_url)\n",
    "    # Direct browser to page\n",
    "    html = browser.html\n",
    "    bom_soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # Focus on 'body' content\n",
    "    main_body = bom_soup.find('div', id='body')\n",
    "\n",
    "    # Focus on the 4th table in body\n",
    "    main_table = main_body.findAll('table')[3]\n",
    "    \n",
    "    # Extract the rows associated with movie links\n",
    "    white_rows = main_table.findAll(\"tr\", bgcolor=\"#ffffff\")\n",
    "    bluey_rows = main_table.findAll(\"tr\", bgcolor=\"#f4f4ff\")\n",
    "\n",
    "    # Extract movie IDs from the links\n",
    "    movie_ids = []\n",
    "    movie_ttl = []\n",
    "\n",
    "    for row in white_rows:\n",
    "        link = row.find('a')\n",
    "        if (link):\n",
    "            addr = link['href'].split('=')[1].split('.')[0]\n",
    "            movie_ids.append(addr)\n",
    "            movie_ttl.append(link.get_text())\n",
    "    for row in bluey_rows:\n",
    "        link = row.find('a')\n",
    "        if (link):\n",
    "            addr = link['href'].split('=')[1].split('.')[0]\n",
    "            movie_ids.append(addr)\n",
    "            movie_ttl.append(link.get_text())\n",
    "\n",
    "    # Scrape the weekly gross data on the targeted movies\n",
    "    movie_pds = []\n",
    "    counter = 0\n",
    "    for ids in movie_ids:\n",
    "        time.sleep(1)\n",
    "        print(f\"{counter}: {ids};\")\n",
    "        wk_html = pd.read_html(data_url + ids + '.htm')\n",
    "        if (wk_html):\n",
    "            # slice column\n",
    "#             wk_col = wk_html[0].iloc[10, :9]\n",
    "\n",
    "            # slice data\n",
    "            wk_pd = wk_html[0].iloc[11:, :9]\n",
    "\n",
    "#             # fix column labels\n",
    "#             wk_col[6:9] = wk_col[5:8]\n",
    "#             wk_col[0] = 'Date'\n",
    "#             wk_col[4:6] = ['Theaters', 'Change']\n",
    "            wk_col = ['Date','Rank','WeeklyGross','%Change',\n",
    "                      'Theaters','Change','Avg.','Gross-to-Date',\n",
    "                      'Week#']\n",
    "            \n",
    "            # set column labels\n",
    "            wk_pd.columns = wk_col\n",
    "            wk_pd.dropna(inplace=True)\n",
    "            wk_pd.reset_index(inplace=True, drop=True)\n",
    "\n",
    "            movie_pds.append(wk_pd)\n",
    "        counter = counter + 1\n",
    "    # Return findings\n",
    "    return {\"titles\":movie_ttl, \"ids\":movie_ids, \"pds\":movie_pds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scrapeFranchiseMovies(id_url, data_url):\n",
    "    browser.visit(id_url)\n",
    "    # Direct browser to page\n",
    "    html = browser.html\n",
    "    bom_soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "    # Focus on 'body' content\n",
    "    main_body = bom_soup.find('div', id='body')\n",
    "\n",
    "    # Focus on the 4th table in body\n",
    "    main_table = main_body.findAll('table')[3]\n",
    "    \n",
    "    # Extract the rows associated with movie links\n",
    "    white_rows = main_table.findAll(\"tr\", bgcolor=\"#ffffff\")\n",
    "    bluey_rows = main_table.findAll(\"tr\", bgcolor=\"#f4f4ff\")\n",
    "\n",
    "    # Extract movie IDs from the links\n",
    "    movie_ids = []\n",
    "    movie_ttl = []\n",
    "    limit = 0\n",
    "    for row in white_rows:\n",
    "        link = row.find('a')\n",
    "        if (link):\n",
    "            addr = link['href'].split('=')[1].split('.')[0]\n",
    "            movie_ids.append(addr)\n",
    "            movie_ttl.append(link.get_text())\n",
    "            limit = limit+1\n",
    "            if (limit == 10): \n",
    "                break\n",
    "    limit = 0\n",
    "    for row in bluey_rows:\n",
    "        link = row.find('a')\n",
    "        if (link):\n",
    "            addr = link['href'].split('=')[1].split('.')[0]\n",
    "            movie_ids.append(addr)\n",
    "            movie_ttl.append(link.get_text())\n",
    "            limit = limit+1\n",
    "            if (limit == 10): \n",
    "                break\n",
    "\n",
    "    # Scrape the weekly gross data on the targeted movies\n",
    "    movie_pds = []\n",
    "    counter = 0\n",
    "    for ids in movie_ids:\n",
    "        time.sleep(1)\n",
    "        print(f\"{counter}: {ids};\")\n",
    "        wk_html = pd.read_html(data_url + ids + '.htm')\n",
    "        if (wk_html):\n",
    "#             # slice column\n",
    "#             wk_col = wk_html[0].iloc[10, :9]\n",
    "\n",
    "            # slice data\n",
    "            wk_pd = wk_html[0].iloc[11:, :9]\n",
    "\n",
    "            # fix column labels\n",
    "#             wk_col[6:9] = wk_col[5:8]\n",
    "#             wk_col[0] = 'Date'\n",
    "#             wk_col[4:6] = ['Theaters', 'Change']\n",
    "            wk_col = ['Date','Rank','WeeklyGross','%Change',\n",
    "                      'Theaters','Change','Avg.','Gross-to-Date',\n",
    "                      'Week#']\n",
    "    \n",
    "            # set column labels\n",
    "            wk_pd.columns = wk_col\n",
    "            wk_pd.dropna(inplace=True)\n",
    "            wk_pd.reset_index(inplace=True, drop=True)\n",
    "\n",
    "            movie_pds.append(wk_pd)\n",
    "        counter = counter + 1\n",
    "    # Return findings\n",
    "    return {\"titles\":movie_ttl, \"ids\":movie_ids, \"pds\":movie_pds}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Direct browser to page\n",
    "# html = browser.html\n",
    "# bom_soup = BeautifulSoup(html, 'html.parser')\n",
    "\n",
    "# # Focus on 'body' content\n",
    "# main_body = bom_soup.find('div', id='body')\n",
    "\n",
    "# # Focus on the 4th table in body\n",
    "# main_table = main_body.findAll('table')[3]\n",
    "\n",
    "# # Inspect html\n",
    "# print(main_table)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract the rows associated with movie links\n",
    "# white_rows = main_table.findAll(\"tr\", bgcolor=\"#ffffff\")\n",
    "# bluey_rows = main_table.findAll(\"tr\", bgcolor=\"#f4f4ff\")\n",
    "\n",
    "# # Examine row structure\n",
    "# print(white_rows[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Extract movie IDs from the links\n",
    "# movie_ids = []\n",
    "# movie_ttl = []\n",
    "\n",
    "# for row in white_rows:\n",
    "#     link = row.find('a')\n",
    "#     if (link):\n",
    "#         addr = link['href'].split('=')[1].split('.')[0]\n",
    "#         movie_ids.append(addr)\n",
    "#         movie_ttl.append(link.get_text())\n",
    "# for row in bluey_rows:\n",
    "#     link = row.find('a')\n",
    "#     if (link):\n",
    "#         addr = link['href'].split('=')[1].split('.')[0]\n",
    "#         movie_ids.append(addr)\n",
    "#         movie_ttl.append(link.get_text())\n",
    "\n",
    "# # Check extraction results\n",
    "# print(len(movie_ids))\n",
    "# for i in range(5):\n",
    "#     print(f\"{movie_ttl[i]}: {movie_ids[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Determine how to scrape movie data from webpage \n",
    "# wk_html = pd.read_html('https://www.boxofficemojo.com/movies/?page=weekly&id=marvel2017b.htm')\n",
    "\n",
    "# # slice column\n",
    "# wk_col = wk_html[0].iloc[10, 0:9]\n",
    "\n",
    "# # slice data\n",
    "# wk_pd = wk_html[0].iloc[11:, 0:9]\n",
    "\n",
    "# # fix column labels\n",
    "# wk_col[6:9] = wk_col[5:8]\n",
    "# wk_col[0] = 'Date'\n",
    "# wk_col[4:6] = ['Theaters', 'Change']\n",
    "\n",
    "# # set column labels\n",
    "# wk_pd.columns = wk_col\n",
    "\n",
    "# # preview results\n",
    "# wk_pd.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Base url for targeted scrape data\n",
    "# wk_base_url = 'https://www.boxofficemojo.com/movies/?page=weekly&id='\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# movie_pds = []\n",
    "# counter = 0\n",
    "# for ids in movie_ids:\n",
    "# #     if((counter > 0) & (counter%20 == 0)):\n",
    "#     time.sleep(1)\n",
    "#     print(f\"{counter}: {ids};\")\n",
    "#     wk_html = pd.read_html(wk_base_url + ids + '.htm')\n",
    "#     if (wk_html):\n",
    "#         # slice column\n",
    "#         wk_col = wk_html[0].iloc[10, :9]\n",
    "\n",
    "#         # slice data\n",
    "#         wk_pd = wk_html[0].iloc[11:, :9]\n",
    "\n",
    "#         # fix column labels\n",
    "#         wk_col[6:9] = wk_col[5:8]\n",
    "#         wk_col[0] = 'Date'\n",
    "#         wk_col[4:6] = ['Theaters', 'Change']\n",
    "\n",
    "#         # set column labels\n",
    "#         wk_pd.columns = wk_col\n",
    "\n",
    "#         movie_pds.append(wk_pd)\n",
    "#     counter = counter + 1\n",
    "    \n",
    "\n",
    "# print(f'\"{movie_ttl[1]}\": {movie_ids[1]}')\n",
    "# movie_pds[1].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function Based Scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common base url\n",
    "base_url = 'https://www.boxofficemojo.com' \n",
    "\n",
    "# Category URL's for scraping:\n",
    "y2018_url = '/yearly/chart/?yr=2018&p=.htm'\n",
    "y2017_url = '/yearly/chart/?yr=2017&p=.htm'\n",
    "y2016_url = '/yearly/chart/?yr=2016&p=.htm'\n",
    "marEU_url = '/franchises/chart/?id=avengers.htm'\n",
    "jBond_url = '/franchises/chart/?id=jamesbond.htm'\n",
    "\n",
    "\n",
    "# Data URL's for scraping:\n",
    "wkly_url = '/movies/?page=weekly&id='"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# res2018 = scrapeMovies(base_url+y2018_url, base_url+wkly_url)\n",
    "# res2018['pds'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: starwars8;\n",
      "1: wonderwoman;\n",
      "2: marvel17a;\n",
      "3: it;\n",
      "4: despicableme3;\n",
      "5: wolverine2017;\n",
      "6: pixar1117;\n",
      "7: blumhouse2;\n",
      "8: bossbaby;\n",
      "9: potc5;\n",
      "10: cars3;\n",
      "11: split2017;\n",
      "12: transformers5;\n",
      "13: fiftyshadesdarker;\n",
      "14: pitchperfect3;\n",
      "15: murderorientexpress17;\n",
      "16: kingsman2;\n",
      "17: johnwick2;\n",
      "18: powerrangers16;\n",
      "19: untitledstevenspielberg;\n",
      "20: hitmansbodyguard;\n",
      "21: captainunderpants;\n",
      "22: adogspurpose;\n",
      "23: ninjago;\n",
      "24: theshack;\n",
      "25: blumhousehorror2018;\n",
      "26: thecoldestcity;\n",
      "27: darktower;\n",
      "28: amadeahalloween2;\n",
      "29: greatwall;\n",
      "30: goinginsty2017;\n",
      "31: xxx3;\n",
      "32: thebigsick;\n",
      "33: thelamb;\n",
      "34: kingarthur2016;\n",
      "35: americanassassin;\n",
      "36: everythingeverything;\n",
      "37: geostorm;\n",
      "38: fistfight;\n",
      "39: kidnap2015;\n",
      "40: mountainbetweenus;\n",
      "41: itonya;\n",
      "42: mollysgame;\n",
      "43: rings;\n",
      "44: homeagain;\n",
      "45: thehouse;\n",
      "46: gifted;\n",
      "47: thebyebyeman;\n",
      "48: rockthatbody;\n",
      "49: leap;\n",
      "50: beautyandthebeast2017;\n",
      "51: jumanji2016;\n",
      "52: spiderman2017;\n",
      "53: marvel2017;\n",
      "54: dcfilm1117;\n",
      "55: furious8;\n",
      "56: chrisnolan2017;\n",
      "57: lego2;\n",
      "58: greatestshowman;\n",
      "59: legendary2016;\n",
      "60: planetoftheapes16;\n",
      "61: wonder;\n",
      "62: girltrip;\n",
      "63: babydriver;\n",
      "64: daddyshome2;\n",
      "65: annabelle2;\n",
      "66: bladerunnersequel;\n",
      "67: theemojimovie;\n",
      "68: ferdinand;\n",
      "69: mummy2016;\n",
      "70: alienparadiselost;\n",
      "71: badmomschristmas;\n",
      "72: theshapeofwater;\n",
      "73: baywatch;\n",
      "74: darkesthour2017;\n",
      "75: threebillboards;\n",
      "76: mena;\n",
      "77: ladybird;\n",
      "78: motherdaughter;\n",
      "79: smurfs3;\n",
      "80: tupac;\n",
      "81: 47metersdown;\n",
      "82: valerian;\n",
      "83: ghostintheshell2017;\n",
      "84: saw2017;\n",
      "85: theforeigner;\n",
      "86: windriver;\n",
      "87: monstertrucks;\n",
      "88: howtobealatinlover;\n",
      "89: underworld5;\n",
      "90: life2017;\n",
      "91: hostiles;\n",
      "92: nutjob2;\n",
      "93: loganlucky;\n",
      "94: residentevil6;\n",
      "95: allthemoneyintheworld;\n",
      "96: downsizing;\n",
      "97: victoriaandabdul;\n",
      "98: mylittlepony2017;\n",
      "99: thedisasterartist;\n"
     ]
    }
   ],
   "source": [
    "res2017 = scrapeMovies(base_url+y2017_url, base_url+wkly_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Rank</th>\n",
       "      <th>WeeklyGross</th>\n",
       "      <th>%Change</th>\n",
       "      <th>Theaters</th>\n",
       "      <th>Change</th>\n",
       "      <th>Avg.</th>\n",
       "      <th>Gross-to-Date</th>\n",
       "      <th>Week#</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Dec 1521</td>\n",
       "      <td>1</td>\n",
       "      <td>$296,602,356</td>\n",
       "      <td>-</td>\n",
       "      <td>4232</td>\n",
       "      <td>-</td>\n",
       "      <td>$70,086</td>\n",
       "      <td>$296,602,356</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Dec 2228</td>\n",
       "      <td>1</td>\n",
       "      <td>$168,095,872</td>\n",
       "      <td>-43.3%</td>\n",
       "      <td>4232</td>\n",
       "      <td>-</td>\n",
       "      <td>$39,720</td>\n",
       "      <td>$464,698,228</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dec 29Jan 4</td>\n",
       "      <td>2</td>\n",
       "      <td>$84,264,374</td>\n",
       "      <td>-49.9%</td>\n",
       "      <td>4232</td>\n",
       "      <td>-</td>\n",
       "      <td>$19,911</td>\n",
       "      <td>$548,962,602</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Jan 511</td>\n",
       "      <td>3</td>\n",
       "      <td>$31,311,982</td>\n",
       "      <td>-62.8%</td>\n",
       "      <td>4232</td>\n",
       "      <td>-</td>\n",
       "      <td>$7,399</td>\n",
       "      <td>$580,274,584</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Jan 1218</td>\n",
       "      <td>5</td>\n",
       "      <td>$17,443,892</td>\n",
       "      <td>-44.3%</td>\n",
       "      <td>3090</td>\n",
       "      <td>-1142</td>\n",
       "      <td>$5,645</td>\n",
       "      <td>$597,718,476</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date Rank   WeeklyGross %Change Theaters Change     Avg.  \\\n",
       "0     Dec 1521    1  $296,602,356       -     4232      -  $70,086   \n",
       "1     Dec 2228    1  $168,095,872  -43.3%     4232      -  $39,720   \n",
       "2  Dec 29Jan 4    2   $84,264,374  -49.9%     4232      -  $19,911   \n",
       "3      Jan 511    3   $31,311,982  -62.8%     4232      -   $7,399   \n",
       "4     Jan 1218    5   $17,443,892  -44.3%     3090  -1142   $5,645   \n",
       "\n",
       "  Gross-to-Date Week#  \n",
       "0  $296,602,356     1  \n",
       "1  $464,698,228     2  \n",
       "2  $548,962,602     3  \n",
       "3  $580,274,584     4  \n",
       "4  $597,718,476     5  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2017['pds'][0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: starwars2016;\n",
      "1: marvel2016;\n",
      "2: junglebook2015;\n",
      "3: disney2016;\n",
      "4: dc2016;\n",
      "5: disney1116;\n",
      "6: marvel716;\n",
      "7: bourne5;\n",
      "8: x-men2016;\n",
      "9: lalaland;\n",
      "10: ghostbusters2016;\n",
      "11: tarzan2016;\n",
      "12: untitledlucasmoore;\n",
      "13: id42;\n",
      "14: arrival2016;\n",
      "15: sausageparty;\n",
      "16: ridealong2;\n",
      "17: peregrine;\n",
      "18: tmnt2016;\n",
      "19: alice2;\n",
      "20: thegirlonthetrain2016;\n",
      "21: storks;\n",
      "22: newline0116;\n",
      "23: allegiant;\n",
      "24: iceage5;\n",
      "25: londonhasfallen;\n",
      "26: deepwaterhorizon;\n",
      "27: mybigfatgreekwedding2;\n",
      "28: fences;\n",
      "29: bfg;\n",
      "30: theshallows;\n",
      "31: assassinscreed;\n",
      "32: 13hoursthesecretsoldiersofbenghazi;\n",
      "33: huntsman;\n",
      "34: manchesterbythesea;\n",
      "35: howtobesingle;\n",
      "36: armsandthedudes;\n",
      "37: moneymonster;\n",
      "38: nerve;\n",
      "39: niceguys;\n",
      "40: dirtygrandpa;\n",
      "41: 5thwave;\n",
      "42: mothersday;\n",
      "43: godsofegypt;\n",
      "44: hailcaesar;\n",
      "45: zoolander2;\n",
      "46: finesthours;\n",
      "47: hellorhighwater;\n",
      "48: benhur2016;\n",
      "49: bridgetjonessbaby;\n",
      "50: pixar2015;\n",
      "51: illumination2015;\n",
      "52: deadpool2016;\n",
      "53: superman2015;\n",
      "54: illumination2016;\n",
      "55: fantasticbeasts;\n",
      "56: hiddenfigures;\n",
      "57: startrek2016;\n",
      "58: trolls;\n",
      "59: kungfupanda3;\n",
      "60: centralintelligence;\n",
      "61: sully;\n",
      "62: angrybirds;\n",
      "63: conjuring2;\n",
      "64: passengers2016;\n",
      "65: themagnificentseven;\n",
      "66: dontbreathe;\n",
      "67: theaccountant;\n",
      "68: purge3;\n",
      "69: petesdragon2016;\n",
      "70: booamadeahalloween;\n",
      "71: badrobot2016;\n",
      "72: hacksawridge;\n",
      "73: nowyouseeme2;\n",
      "74: michelledarnell;\n",
      "75: miraclesfromheaven;\n",
      "76: whyhim;\n",
      "77: jackreacher2;\n",
      "78: mebeforeyou;\n",
      "79: universalcomedy2016;\n",
      "80: officechristmasparty;\n",
      "81: barbershop3;\n",
      "82: lion;\n",
      "83: kuboandthetwostrings;\n",
      "84: warcraft;\n",
      "85: mikeanddave;\n",
      "86: ameyerschristmas;\n",
      "87: pittcotillard;\n",
      "88: risen;\n",
      "89: boy2016;\n",
      "90: blumhouse3;\n",
      "91: inferno2015;\n",
      "92: patriotsday;\n",
      "93: collateralbeauty;\n",
      "94: whentheboughbreaks;\n",
      "95: moonlight2016;\n",
      "96: florencefosterjenkins;\n",
      "97: forest;\n",
      "98: thewitch;\n",
      "99: kevinhart2016;\n"
     ]
    }
   ],
   "source": [
    "res2016 = scrapeMovies(base_url+y2016_url, base_url+wkly_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: marvel2017b;\n",
      "1: avengers11;\n",
      "2: ironman3;\n",
      "3: marvel17a;\n",
      "4: marvel2014a;\n",
      "5: marvel2017;\n",
      "6: marvel14b;\n",
      "7: ant-manandthewasp;\n",
      "8: thor;\n",
      "9: captainamerica;\n",
      "10: marvel0518;\n",
      "11: avengers2;\n",
      "12: marvel2016;\n",
      "13: spiderman2017;\n",
      "14: ironman;\n",
      "15: ironman2;\n",
      "16: marvel716;\n",
      "17: thor2;\n",
      "18: antman;\n",
      "19: incrediblehulk;\n"
     ]
    }
   ],
   "source": [
    "resMarCU = scrapeFranchiseMovies(base_url+marEU_url, base_url+wkly_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Rank</th>\n",
       "      <th>WeeklyGross</th>\n",
       "      <th>%Change</th>\n",
       "      <th>Theaters</th>\n",
       "      <th>Change</th>\n",
       "      <th>Avg.</th>\n",
       "      <th>Gross-to-Date</th>\n",
       "      <th>Week#</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Feb 1622</td>\n",
       "      <td>1</td>\n",
       "      <td>$291,954,422</td>\n",
       "      <td>-</td>\n",
       "      <td>4020</td>\n",
       "      <td>-</td>\n",
       "      <td>$72,625</td>\n",
       "      <td>$291,954,422</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Feb 23Mar 1</td>\n",
       "      <td>1</td>\n",
       "      <td>$143,445,615</td>\n",
       "      <td>-50.9%</td>\n",
       "      <td>4020</td>\n",
       "      <td>-</td>\n",
       "      <td>$35,683</td>\n",
       "      <td>$435,400,037</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Mar 28</td>\n",
       "      <td>1</td>\n",
       "      <td>$85,479,564</td>\n",
       "      <td>-40.4%</td>\n",
       "      <td>4084</td>\n",
       "      <td>+64</td>\n",
       "      <td>$20,930</td>\n",
       "      <td>$520,879,601</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Mar 915</td>\n",
       "      <td>1</td>\n",
       "      <td>$57,496,927</td>\n",
       "      <td>-32.7%</td>\n",
       "      <td>3942</td>\n",
       "      <td>-142</td>\n",
       "      <td>$14,586</td>\n",
       "      <td>$578,376,528</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Mar 1622</td>\n",
       "      <td>1</td>\n",
       "      <td>$35,881,708</td>\n",
       "      <td>-37.6%</td>\n",
       "      <td>3834</td>\n",
       "      <td>-108</td>\n",
       "      <td>$9,359</td>\n",
       "      <td>$614,258,236</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date Rank   WeeklyGross %Change Theaters Change     Avg.  \\\n",
       "0     Feb 1622    1  $291,954,422       -     4020      -  $72,625   \n",
       "1  Feb 23Mar 1    1  $143,445,615  -50.9%     4020      -  $35,683   \n",
       "2       Mar 28    1   $85,479,564  -40.4%     4084    +64  $20,930   \n",
       "3      Mar 915    1   $57,496,927  -32.7%     3942   -142  $14,586   \n",
       "4     Mar 1622    1   $35,881,708  -37.6%     3834   -108   $9,359   \n",
       "\n",
       "  Gross-to-Date Week#  \n",
       "0  $291,954,422     1  \n",
       "1  $435,400,037     2  \n",
       "2  $520,879,601     3  \n",
       "3  $578,376,528     4  \n",
       "4  $614,258,236     5  "
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resMarCU['pds'][0].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "### Transformation\n",
    "- Convert PDs to a csv format for chord diagram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Determine how to reformat dates\n",
    "# dates = res2018['pds'][0]['Date']\n",
    "# dates\n",
    "# for date in dates:\n",
    "#     p_date = date.split('')[0].split(' ')\n",
    "#     if (len(p_date[1])==1):\n",
    "#         p_date[1] = '0'+ p_date[1]\n",
    "#     start_str = \"-\".join(p_date)+'-18'\n",
    "#     start_date = dt.strptime(start_str, '%b-%d-%y')\n",
    "#     week_nm = start_date.strftime('%U')\n",
    "# #     print(f\"{start_str} = week # {week_nm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'52'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# function to convert weekend to calendar week number \n",
    "def getWkNum(datestring, yr):\n",
    "    p_date = datestring.split('')[0].split(' ')\n",
    "    if (len(p_date[1])==1):\n",
    "        p_date[1] = '0'+ p_date[1]\n",
    "    start_str = '-'.join(p_date) + f'-{yr}'\n",
    "    start_date = dt.strptime(start_str, '%b-%d-%y')\n",
    "    return start_date.strftime('%U')\n",
    "\n",
    "getWkNum(\"Dec 30\", 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to convert gross strings into numbers\n",
    "def stripUSD(amount):\n",
    "    return ''.join(amount.replace('$', '').split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cal2018_cols = ['Year', 'BOM_id', 'Movie']\n",
    "# cal_rows = []\n",
    "# for i in np.arange(53):\n",
    "#     lbl = i\n",
    "#     if i < 10:\n",
    "#         lbl = f'0{i}'\n",
    "#     cal2018_cols.append(f'W_{lbl}')\n",
    "# for i in np.arange(53):\n",
    "#     lbl = i\n",
    "#     if i < 10:\n",
    "#         lbl = f'0{i}'\n",
    "#     cal2018_cols.append(f'T_{lbl}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # for each movie in the list\n",
    "# for i in np.arange(len(res2018['pds'])):\n",
    "#     # get the title and id to start the row\n",
    "#     new_row = ['2018', res2018['ids'][i], res2018['titles'][i]]\n",
    "#     # add in 0's \n",
    "#     for j in np.arange(106):\n",
    "#         new_row.append('0')\n",
    "\n",
    "#     itr_pds = res2018['pds'][i]\n",
    "#     last_col = 56\n",
    "#     last_grs = 0\n",
    "#     for ind, row in itr_pds.iterrows():\n",
    "#         calWkNum = getWkNum(row['Date'], 18)\n",
    "# #         print(f\"row {i}: {calWkNum} > {int(calWkNum)+3} = {row['WeeklyGross']} > {int(calWkNum)+56} = {row['Gross-to-Date']}\")\n",
    "#         last_col = 56 + int(calWkNum)\n",
    "#         last_grs = stripUSD(row['Gross-to-Date'])\n",
    "#         new_row[3 + int(calWkNum)] = stripUSD(row['WeeklyGross'])\n",
    "#         new_row[last_col] = last_grs\n",
    "#     for j in np.arange(last_col+1, 109):\n",
    "#         new_row[j] = last_grs\n",
    "#     cal_rows.append(new_row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# m2018cal_df = pd.DataFrame(cal_rows, columns=cal2018_cols)\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#     display(m2018cal_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m2018cal_df.to_csv('Data/caly_mov_gross_2018.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Create column labels\n",
    "# wkl2018_cols = ['Year', 'BOM_id', 'Movie']\n",
    "# wkl_rows = []\n",
    "\n",
    "# for i in np.arange(52):\n",
    "#     lbl = i+1\n",
    "#     if lbl < 10:\n",
    "#         lbl = f'0{lbl}'\n",
    "#     wkl2018_cols.append(f'W_{lbl}')\n",
    "# for i in np.arange(52):\n",
    "#     lbl = i+1\n",
    "#     if lbl < 10:\n",
    "#         lbl = f'0{lbl}'\n",
    "#     wkl2018_cols.append(f'T_{lbl}')\n",
    "\n",
    "# # Look for the longest movie duration\n",
    "# max_dur = 0\n",
    "\n",
    "# # Make a row for each movie in the list\n",
    "# for i in np.arange(len(res2018['pds'])):\n",
    "#     # get the title and id to start the row\n",
    "#     new_row = ['2018', res2018['ids'][i], res2018['titles'][i]]\n",
    "#     # add in 0's \n",
    "#     for j in np.arange(104):\n",
    "#         new_row.append('0')\n",
    "\n",
    "#     itr_pds = res2018['pds'][i]\n",
    "#     last_col = 56\n",
    "#     last_grs = 0\n",
    "#     row_count = itr_pds.shape[0]\n",
    "#     if (row_count > max_dur):\n",
    "#         max_dur = row_count\n",
    "    \n",
    "#     for ind, row in itr_pds.iterrows():\n",
    "#         #wkNum = row['Week#']\n",
    "#         last_col = 55 + ind\n",
    "#         last_grs = stripUSD(row['Gross-to-Date'])\n",
    "#         new_row[3 + ind] = stripUSD(row['WeeklyGross'])\n",
    "#         new_row[last_col] = last_grs\n",
    "#     for j in np.arange(last_col+1, 107):\n",
    "#         new_row[j] = last_grs\n",
    "#     wkl_rows.append(new_row)\n",
    "\n",
    "# # Check the longest running movie\n",
    "# print(max_dur)\n",
    "\n",
    "# # Create dataframe out of columns and rows\n",
    "# m2018wkl_df = pd.DataFrame(wkl_rows, columns=wkl2018_cols)\n",
    "# with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "#     display(m2018wkl_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m2018wkl_df.to_csv('Data/wkly_mov_gross_2018.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function Based Transformation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_movie(scrape_res, affix, year):\n",
    "#     cal_cols = ['Year', 'BOM_id', 'Movie']\n",
    "#     cal_rows = []\n",
    "    \n",
    "#     for i in np.arange(53):\n",
    "#         lbl = i\n",
    "#         if i < 10:\n",
    "#             lbl = f'0{i}'\n",
    "#         cal_cols.append(f'W_{lbl}')\n",
    "    \n",
    "#     for i in np.arange(53):\n",
    "#         lbl = i\n",
    "#         if i < 10:\n",
    "#             lbl = f'0{i}'\n",
    "#         cal_cols.append(f'T_{lbl}')\n",
    "        \n",
    "#     # for each movie in the list\n",
    "#     for i in np.arange(len(scrape_res['pds'])):\n",
    "#         # get the title and id to start the row\n",
    "#         new_row = [year, scrape_res['ids'][i], scrape_res['titles'][i]]\n",
    "#         # add in 0's \n",
    "#         for j in np.arange(106):\n",
    "#             new_row.append('0')\n",
    "\n",
    "#         itr_pds = scrape_res['pds'][i]\n",
    "#         last_col = 56\n",
    "#         last_grs = 0\n",
    "#         for ind, row in itr_pds.iterrows():\n",
    "#             calWkNum = getWkNum(row['Date'], year)\n",
    "#             last_col = 56 + int(calWkNum)\n",
    "#             last_grs = stripUSD(row['Gross-to-Date'])\n",
    "#             new_row[3 + int(calWkNum)] = stripUSD(row['WeeklyGross'])\n",
    "#             new_row[last_col] = last_grs\n",
    "#         for j in np.arange(last_col+1, 109):\n",
    "#             new_row[j] = last_grs\n",
    "#         cal_rows.append(new_row)\n",
    "    \n",
    "#     mov_cal_df = pd.DataFrame(cal_rows, columns=cal_cols)\n",
    "#     save_path = f'Data/caly_mov_gross_{affix}.csv'\n",
    "#     mov_cal_df.to_csv(save_path, index=False)\n",
    "    \n",
    "    # Create column labels\n",
    "    wkl_cols = ['Year', 'BOM_id', 'Movie']\n",
    "    wkl_rows = []\n",
    "\n",
    "    for i in np.arange(52):\n",
    "        lbl = i+1\n",
    "        if lbl < 10:\n",
    "            lbl = f'0{lbl}'\n",
    "        wkl_cols.append(f'W_{lbl}')\n",
    "    for i in np.arange(52):\n",
    "        lbl = i+1\n",
    "        if lbl < 10:\n",
    "            lbl = f'0{lbl}'\n",
    "        wkl_cols.append(f'T_{lbl}')\n",
    "\n",
    "    # Look for the longest movie duration\n",
    "    max_dur = 0\n",
    "\n",
    "    # Make a row for each movie in the list\n",
    "    for i in np.arange(len(scrape_res['pds'])):\n",
    "        # get the title and id to start the row\n",
    "        new_row = [year, scrape_res['ids'][i], scrape_res['titles'][i]]\n",
    "        # add in 0's \n",
    "        for j in np.arange(104):\n",
    "            new_row.append('0')\n",
    "\n",
    "        itr_pds = scrape_res['pds'][i]\n",
    "        last_col = 56\n",
    "        last_grs = 0\n",
    "        row_count = itr_pds.shape[0]\n",
    "        if (row_count > max_dur):\n",
    "            max_dur = row_count\n",
    "\n",
    "        for ind, row in itr_pds.iterrows():\n",
    "            #wkNum = row['Week#']\n",
    "            last_col = 55 + ind\n",
    "            try:\n",
    "                last_grs = stripUSD(row['Gross-to-Date'])\n",
    "            except:\n",
    "                print(f'{i}: {scrape_res[\"titles\"][i]} >>')\n",
    "                print(row)\n",
    "            new_row[3 + ind] = stripUSD(row['WeeklyGross'])\n",
    "            new_row[last_col] = last_grs\n",
    "        for j in np.arange(last_col+1, 107):\n",
    "            new_row[j] = last_grs\n",
    "        wkl_rows.append(new_row)\n",
    "        \n",
    "    mov_wkl_df = pd.DataFrame(wkl_rows, columns=wkl_cols)\n",
    "    save_path = f'Data/wkly_mov_gross_{affix}.csv'\n",
    "    mov_wkl_df.to_csv(save_path, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Rank</th>\n",
       "      <th>WeeklyGross</th>\n",
       "      <th>%Change</th>\n",
       "      <th>Theaters</th>\n",
       "      <th>Change</th>\n",
       "      <th>Avg.</th>\n",
       "      <th>Gross-to-Date</th>\n",
       "      <th>Week#</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Nov 1723</td>\n",
       "      <td>7</td>\n",
       "      <td>$15,157,196</td>\n",
       "      <td>-</td>\n",
       "      <td>2837</td>\n",
       "      <td>-</td>\n",
       "      <td>$5,343</td>\n",
       "      <td>$15,157,196</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nov 2430</td>\n",
       "      <td>7</td>\n",
       "      <td>$8,122,457</td>\n",
       "      <td>-46.4%</td>\n",
       "      <td>2837</td>\n",
       "      <td>-</td>\n",
       "      <td>$2,863</td>\n",
       "      <td>$23,279,653</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Dec 17</td>\n",
       "      <td>9</td>\n",
       "      <td>$5,324,393</td>\n",
       "      <td>-34.4%</td>\n",
       "      <td>2822</td>\n",
       "      <td>-15</td>\n",
       "      <td>$1,887</td>\n",
       "      <td>$28,604,046</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Dec 814</td>\n",
       "      <td>9</td>\n",
       "      <td>$4,996,174</td>\n",
       "      <td>-6.2%</td>\n",
       "      <td>2976</td>\n",
       "      <td>+154</td>\n",
       "      <td>$1,679</td>\n",
       "      <td>$33,600,220</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Dec 1521</td>\n",
       "      <td>12</td>\n",
       "      <td>$3,491,705</td>\n",
       "      <td>-30.1%</td>\n",
       "      <td>1491</td>\n",
       "      <td>-1485</td>\n",
       "      <td>$2,342</td>\n",
       "      <td>$37,091,925</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Dec 2228</td>\n",
       "      <td>18</td>\n",
       "      <td>$2,387,128</td>\n",
       "      <td>-31.6%</td>\n",
       "      <td>1106</td>\n",
       "      <td>-385</td>\n",
       "      <td>$2,158</td>\n",
       "      <td>$39,479,053</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Dec 29Jan 4</td>\n",
       "      <td>25</td>\n",
       "      <td>$828,546</td>\n",
       "      <td>-65.3%</td>\n",
       "      <td>661</td>\n",
       "      <td>-445</td>\n",
       "      <td>$1,253</td>\n",
       "      <td>$40,307,599</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Jan 511</td>\n",
       "      <td>30</td>\n",
       "      <td>$174,226</td>\n",
       "      <td>-79.0%</td>\n",
       "      <td>268</td>\n",
       "      <td>-393</td>\n",
       "      <td>$650</td>\n",
       "      <td>$40,481,825</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Jan 1218</td>\n",
       "      <td>33</td>\n",
       "      <td>$160,107</td>\n",
       "      <td>-8.1%</td>\n",
       "      <td>160</td>\n",
       "      <td>-108</td>\n",
       "      <td>$1,001</td>\n",
       "      <td>$40,641,932</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Jan 1925</td>\n",
       "      <td>38</td>\n",
       "      <td>$90,681</td>\n",
       "      <td>-43.4%</td>\n",
       "      <td>132</td>\n",
       "      <td>-28</td>\n",
       "      <td>$687</td>\n",
       "      <td>$40,732,613</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>Jan 26Feb 1</td>\n",
       "      <td>41</td>\n",
       "      <td>$64,957</td>\n",
       "      <td>-28.4%</td>\n",
       "      <td>97</td>\n",
       "      <td>-35</td>\n",
       "      <td>$670</td>\n",
       "      <td>$40,797,570</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>Feb 28</td>\n",
       "      <td>48</td>\n",
       "      <td>$35,699</td>\n",
       "      <td>-45.0%</td>\n",
       "      <td>72</td>\n",
       "      <td>-25</td>\n",
       "      <td>$496</td>\n",
       "      <td>$40,833,269</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>Feb 915</td>\n",
       "      <td>60</td>\n",
       "      <td>$19,555</td>\n",
       "      <td>-45.2%</td>\n",
       "      <td>50</td>\n",
       "      <td>-22</td>\n",
       "      <td>$391</td>\n",
       "      <td>$40,852,824</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date Rank  WeeklyGross %Change Theaters Change    Avg.  \\\n",
       "0      Nov 1723    7  $15,157,196       -     2837      -  $5,343   \n",
       "1      Nov 2430    7   $8,122,457  -46.4%     2837      -  $2,863   \n",
       "2        Dec 17    9   $5,324,393  -34.4%     2822    -15  $1,887   \n",
       "3       Dec 814    9   $4,996,174   -6.2%     2976   +154  $1,679   \n",
       "4      Dec 1521   12   $3,491,705  -30.1%     1491  -1485  $2,342   \n",
       "5      Dec 2228   18   $2,387,128  -31.6%     1106   -385  $2,158   \n",
       "6   Dec 29Jan 4   25     $828,546  -65.3%      661   -445  $1,253   \n",
       "7       Jan 511   30     $174,226  -79.0%      268   -393    $650   \n",
       "8      Jan 1218   33     $160,107   -8.1%      160   -108  $1,001   \n",
       "9      Jan 1925   38      $90,681  -43.4%      132    -28    $687   \n",
       "10  Jan 26Feb 1   41      $64,957  -28.4%       97    -35    $670   \n",
       "11       Feb 28   48      $35,699  -45.0%       72    -25    $496   \n",
       "12      Feb 915   60      $19,555  -45.2%       50    -22    $391   \n",
       "\n",
       "   Gross-to-Date Week#  \n",
       "0    $15,157,196     1  \n",
       "1    $23,279,653     2  \n",
       "2    $28,604,046     3  \n",
       "3    $33,600,220     4  \n",
       "4    $37,091,925     5  \n",
       "5    $39,479,053     6  \n",
       "6    $40,307,599     7  \n",
       "7    $40,481,825     8  \n",
       "8    $40,641,932     9  \n",
       "9    $40,732,613    10  \n",
       "10   $40,797,570    11  \n",
       "11   $40,833,269    12  \n",
       "12   $40,852,824    13  "
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "res2017['pds'][33]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_movie(res2017, \"2017\", 17)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_movie(res2016, \"2016\", 16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_movie(resMarCU, \"MCU\", 18)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
